{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CxxIPBBQBdt"
      },
      "outputs": [],
      "source": [
        "import zipfile  # For handling zip files\n",
        "import io  # For input/output operations\n",
        "import os  # For operating system related operations\n",
        "import torch  # PyTorch library for deep learning\n",
        "import pandas as pd  # For data manipulation and analysis\n",
        "from torch.utils.data import Dataset  # For creating custom datasets\n",
        "from sklearn.model_selection import train_test_split  # For splitting data into train/test sets\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments  # BERT-related components\n",
        "import numpy as np  # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For plotting\n",
        "from google.colab import files  # For handling file uploads in Google Colab\n",
        "from sklearn.metrics import accuracy_score  # For calculating model accuracy\n",
        "\n",
        "# Upload the zip file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded file\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {filename}\")\n",
        "\n",
        "# Create dataset directory if it doesn't exist\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "zip_file = uploaded[filename]\n",
        "with zipfile.ZipFile(io.BytesIO(zip_file), 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n",
        "\n",
        "# List all files in the dataset directory\n",
        "print(\"\\nFiles in dataset directory:\")\n",
        "for file in os.listdir('dataset'):\n",
        "    print(f\"- {file}\")\n",
        "\n",
        "# Find the first CSV file in the directory\n",
        "csv_files = [f for f in os.listdir('dataset') if f.endswith('.csv')]\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(\"No CSV files found in the extracted contents\")\n",
        "\n",
        "# Use the first CSV file found\n",
        "data_path = os.path.join('dataset', csv_files[0])\n",
        "print(f\"\\nLoading CSV file: {data_path}\")\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Number of rows: {len(df)}\")\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text', 'class']]\n",
        "\n",
        "# Convert categorical labels to binary values: 'suicide' -> 1, 'non-suicide' -> 0\n",
        "df['class'] = df['class'].map({'suicide': 1, 'non-suicide': 0})\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_texts, val_texts, train_classes, val_classes = train_test_split(\n",
        "    df['text'].tolist(),  # Convert text column to list\n",
        "    df['class'].tolist(),  # Convert class column to list\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Initialize the BERT tokenizer with pre-trained weights\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the training texts\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=256)\n",
        "\n",
        "# Create a custom Dataset class for the suicide detection task\n",
        "class SuicideDetectionDataset(Dataset):\n",
        "    def __init__(self, encodings, classes):\n",
        "        self.encodings = encodings  # Store tokenized texts\n",
        "        self.classes = classes  # Store corresponding labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.classes)  # Return number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert encodings to PyTorch tensors for a given index\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # Add the label as a tensor\n",
        "        item['labels'] = torch.tensor(self.classes[idx])\n",
        "        return item\n",
        "\n",
        "# Create training and validation datasets using the custom Dataset class\n",
        "train_dataset = SuicideDetectionDataset(train_encodings, train_classes)\n",
        "val_dataset = SuicideDetectionDataset(val_encodings, val_classes)"
      ],
      "metadata": {
        "id": "G9AsViSUQdiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable Weights & Biases logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Initialize BERT model for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "id": "9-E5cbkOf5UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments/hyperparameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Directory to save model checkpoints\n",
        "    num_train_epochs=3,  # Number of training epochs\n",
        "    per_device_train_batch_size=8,  # Training batch size per device\n",
        "    per_device_eval_batch_size=8,  # Evaluation batch size per device\n",
        "    warmup_steps=500,  # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,  # Weight decay for regularization\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=10,  # Log every 10 steps\n",
        "    evaluation_strategy=\"steps\",  # When to perform evaluation\n",
        "    eval_steps=100,  # Evaluate every 100 steps\n",
        "    save_strategy=\"steps\",  # When to save model checkpoints\n",
        "    save_steps=100,  # Save model every 100 steps\n",
        "    save_total_limit=3,  # Maximum number of checkpoints to keep\n",
        "    report_to=None  # Disable external reporting\n",
        ")\n",
        "\n",
        "# Define function to compute evaluation metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)  # Convert logits to predictions\n",
        "    return {\"eval_accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,  # The pretrained model\n",
        "    args=training_args,  # Training arguments\n",
        "    train_dataset=train_dataset,  # Training dataset\n",
        "    eval_dataset=val_dataset,  # Validation dataset\n",
        "    compute_metrics=compute_metrics  # Metrics computation function\n",
        ")\n",
        "\n",
        "# Start the training process\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ARAUNlxYgBBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n",
        "\n",
        "# Get the training logs that contain evaluation metrics\n",
        "training_logs = trainer.state.log_history\n",
        "\n",
        "# Initialize lists to store evaluation steps, accuracy values, and training loss\n",
        "eval_steps = []\n",
        "accuracy_vals = []\n",
        "train_steps = []\n",
        "train_loss = []\n",
        "\n",
        "# Extract evaluation steps, accuracy values, and training loss from the logs\n",
        "for log in training_logs:\n",
        "   # Extract evaluation accuracy\n",
        "   if 'eval_accuracy' in log:\n",
        "       eval_steps.append(log['step'])\n",
        "       accuracy_vals.append(log['eval_accuracy'] * 100)\n",
        "\n",
        "   # Extract training loss\n",
        "   if 'loss' in log and 'eval_loss' not in log:  # Make sure we're getting training loss, not eval loss\n",
        "       train_steps.append(log['step'])\n",
        "       train_loss.append(log['loss'])\n",
        "\n",
        "# Create a figure with two subplots side by side\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "if eval_steps:\n",
        "   plt.plot(eval_steps, accuracy_vals, label='Accuracy', color='blue')\n",
        "   plt.xlabel('Evaluation Step')\n",
        "   plt.ylabel('Accuracy (%)')\n",
        "   plt.title('Model Accuracy over Time')\n",
        "   plt.ylim(0, 100)\n",
        "   plt.xlim(0, max(eval_steps))\n",
        "   plt.legend()\n",
        "else:\n",
        "   print(\"No evaluation steps found in logs.\")\n",
        "\n",
        "# Plot training loss\n",
        "plt.subplot(1, 2, 2)\n",
        "if train_steps:\n",
        "   plt.plot(train_steps, train_loss, label='Training Loss', color='red')\n",
        "   plt.xlabel('Training Step')\n",
        "   plt.ylabel('Loss')\n",
        "   plt.title('Training Loss over Time')\n",
        "   plt.legend()\n",
        "else:\n",
        "   print(\"No training steps found in logs.\")\n",
        "\n",
        "# Adjust layout and display plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained('./suicide_detection_model')"
      ],
      "metadata": {
        "id": "Nc6sXn0BQ7nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    # Move model to the specified device if not already done\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenize and move input to the same device as the model\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Run prediction\n",
        "    with torch.no_grad():  # Add this for inference efficiency\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=1)\n",
        "\n",
        "    # Return prediction\n",
        "    return \"Suicidal\" if prediction.item() == 1 else \"Non-Suicidal\"\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    test_text = \"I don't think I can do this anymore\"\n",
        "    result = predict(test_text)\n",
        "    print(result)\n",
        "\n",
        "    # Important: If you're done with GPU operations, you can free up memory\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error during prediction: {e}\")\n",
        "    print(\"Please ensure your model and tokenizer are properly loaded\")"
      ],
      "metadata": {
        "id": "s6ZK0jwlT8r1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
